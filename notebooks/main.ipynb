{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv\n",
    "import pathlib as pb\n",
    "import sys\n",
    "\n",
    "\n",
    "# Add `ape` package to SYS path\n",
    "sys.path.append(str(pb.Path(find_dotenv()).parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, cast\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import evaluate as eval\n",
    "import lightning as lit\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from dataclasses import asdict\n",
    "from transformers import AlbertTokenizer\n",
    "from collections import defaultdict, namedtuple\n",
    "from transformers import AutoModel, AutoTokenizer, XLMRobertaForCausalLM\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt.onmt.modules.position_ffn import ActivationFunction\n",
    "from onmt.onmt.translate.translator import GeneratorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ape\n",
    "from ape.data.types import DataSplit\n",
    "from ape.data.types import APETripletDict\n",
    "from ape.eval.metrics import APEMetrics\n",
    "from ape.data.dataset import APEDataset\n",
    "from ape.data.transform import Tokenize, HFTokenizer\n",
    "from ape.model.mst import MultiSourceTransformerCausalLM\n",
    "from ape.model.encoders import MultiSourceTransformerEncoder\n",
    "from ape.model.decoders import MultiSourceTransformerDecoder\n",
    "from ape.light.causal_lm import MultiSourceCausalLMLightningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TER, chrF and BLEU\n",
    "metrics = APEMetrics(cache_dir=ape.HF_CACHE_DIR)\n",
    "\n",
    "# Load APE Dataset (Original + Synthetic)\n",
    "ds_test = APEDataset(path=ape.DATA_DIR, split='test')\n",
    "ds_train = APEDataset(path=ape.DATA_DIR, split='train')\n",
    "ds_train, ds_valid = random_split(ds_train, lengths=[0.99, 0.01], generator=ape.gen_torch)\n",
    "\n",
    "# Aggregate all subsets into a single object\n",
    "ds: Dict[DataSplit, Dataset[APETripletDict[str]]] = {\n",
    "    'train': ds_train,\n",
    "    'valid': ds_valid,\n",
    "    'test': ds_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose encoders for each input type\n",
    "encoder_type_src = 'roberta-base'\n",
    "encoder_type_mt = 'l3cube-pune/marathi-roberta'\n",
    "\n",
    "# Load source and target tokenizers\n",
    "hf_tokenizer_src = AutoTokenizer.from_pretrained(encoder_type_src,\n",
    "                                                                                 use_fast=True,\n",
    "                                                                                 padding_side='right',\n",
    "                                                                                 truncation_side='right',\n",
    "                                                                                 cache_dir=ape.HF_CACHE_DIR / 'tokenizers')\n",
    "hf_tokenizer_mt = AutoTokenizer.from_pretrained(encoder_type_mt,\n",
    "                                                                                use_fast=True,\n",
    "                                                                                padding_side='right',\n",
    "                                                                                truncation_side='right',\n",
    "                                                                                cache_dir=ape.HF_CACHE_DIR / 'tokenizers')\n",
    "\n",
    "# Wrap and customize HF Tokenizers\n",
    "max_seq_len = 512\n",
    "tokenizer_src = HFTokenizer(hf_tokenizer_src, source_prefix='src', max_length=max_seq_len)\n",
    "tokenizer_mt = HFTokenizer(hf_tokenizer_mt, source_prefix='mt', max_length=max_seq_len)\n",
    "tokenizer_pe = HFTokenizer(hf_tokenizer_mt, source_prefix='pe', max_length=max_seq_len)\n",
    "tokenize = Tokenize([tokenizer_src, tokenizer_mt, tokenizer_pe])\n",
    "\n",
    "# Use same settings across all splits\n",
    "DefaultDataLoader = partial(DataLoader,\n",
    "                            collate_fn=tokenize,\n",
    "                            num_workers=ape.WORKERS,\n",
    "                            batch_size=ape.BATCH_SIZE,\n",
    "                            prefetch_factor=ape.PREFETCH_FACTOR)\n",
    "\n",
    "# Aggregate all dataloaders into a single object\n",
    "dl: Dict[DataSplit, DataLoader] = {\n",
    "    'train': DefaultDataLoader(ds['train']),\n",
    "    'valid': DefaultDataLoader(ds['valid']),\n",
    "    'test': DefaultDataLoader(ds['test']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = MultiSourceCausalLMLightningModule(\n",
    "    bos_token_id=hf_tokenizer_mt.bos_token_id,\n",
    "    encoder_type_src=encoder_type_src,\n",
    "    encoder_type_mt=encoder_type_mt,\n",
    "    tokenizer_mt=hf_tokenizer_mt,\n",
    "    block_size=max_seq_len,\n",
    "    temperature=1.0,\n",
    "    do_sample=True,\n",
    "    top_k=8,\n",
    ")\n",
    "\n",
    "logger = MLFlowLogger(\n",
    "    experiment_name='Automatic Post-Editing',\n",
    "    tracking_uri=ape.MLFLOW_TRACKING_URI,\n",
    "    tags={ 'test': 'true', },\n",
    ")\n",
    "\n",
    "trainer = lit.Trainer(\n",
    "    logger=logger,\n",
    "    limit_val_batches=200,\n",
    "    val_check_interval=5_000,\n",
    "    accumulate_grad_batches=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/.cache/pypoetry/virtualenvs/ape-zcZ_0igR-py3.11/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                           | Params\n",
      "---------------------------------------------------------\n",
      "0 | model | MultiSourceTransformerCausalLM | 629 M \n",
      "---------------------------------------------------------\n",
      "629 M     Trainable params\n",
      "0         Non-trainable params\n",
      "629 M     Total params\n",
      "2,519.085 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634a19d311794014a64b075cfca09875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/.cache/pypoetry/virtualenvs/ape-zcZ_0igR-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/invokariman/.cache/pypoetry/virtualenvs/ape-zcZ_0igR-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bac4f562355466ba1a78fe13c3602de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8df9fe97df34f0e824c64cd0c811c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecab03fedae4ff090308b66ea115024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7e3deadaad49369ddb32ddc7c63111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02546e09bf3440068f6f202c7386c6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92e347b9bab42dea497d64721b7b87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ade2dbbfec401ba873f0a06d78e22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f66e25c56694feb96b010ceba74a63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8584fdd0da144c478408ebcebbf9cb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580c5d68f2004fdca76cfea21b6c839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b29e1f611a84344b4c884b34224556f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46678c09b8d4e1fa719d213933ef336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf57b748821446239d7c6a043c0660e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1e0f6629c740eebeda5c9ae6c41edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7496ce8b8b48cf997dc8e8145d47cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0963ca2e194759a33bb8cbfbba851c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5a4fdde3cf4b7a90bdfb6144f22c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e11e58148b342fba8117482cda13ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443388fbe6a9405a96aec2708d4af075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/.cache/pypoetry/virtualenvs/ape-zcZ_0igR-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=dl['train'], val_dataloaders=dl['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), ape.ROOT_DIR / '..'/ 'ckpt' / 'weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a batch of examples\n",
    "batch = next(iter(dl['test']))\n",
    "\n",
    "# Apply Automatic Post-Editing\n",
    "post_edit = model.model.post_edit(\n",
    "    src_input_ids=batch['src_input_ids'].to(ape.DEVICE),\n",
    "    mt_input_ids=batch['mt_input_ids'].to(ape.DEVICE),\n",
    "    src_attn_mask=batch['src_attention_mask'].to(ape.DEVICE),\n",
    "    mt_attn_mask=batch['mt_attention_mask'].to(ape.DEVICE),\n",
    "    bos_token_id=hf_tokenizer_mt.bos_token_id,\n",
    "    temperature=1.0,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>Section  A  will  be  of  Multiple-Choice  Questions (MCQs)  and  Section  B  will  contain  Questions  whose  answers  are  to  be  filled  in  as  a numerical value.</s>',\n",
       " '<s>God can be achieved only through complete devotion, he preached.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>Itchy red skin (where you had the injection) – apply a soothing cream such as a moisturiser, anti-itch cream or lotion.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>If you or your child has nf2, your clinical team will pass information about you/your child on to the national congenital anomaly and rare disease registration service (ncardrs).</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the SRC\n",
    "hf_tokenizer_src.batch_decode(batch['src_input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> 'अ' विभागात बहुपर्यायी प्रश्न असतील आणि 'ब' विभागात संख्यात्मक मूल्याचे प्रश्न असतील.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n",
       " '<s> \"पूर्ण भक्तीनेच देव प्राप्त होऊ शकतो,\" असे त्यांनी प्रचार केले.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> लाल त्वचा (जिथे तुम्हाला इंजेक्शन देण्यात आले आहे)-मॉइस्चरायझर, अँटी-इच क्रीम किंवा लोशन सारख्या शामक क्रीम लावा.</s>',\n",
       " '<s> समुद्राच्या पातळीवर, बॅरॅक, तुरुंग, बंदुकीच्या पावडरसाठी साठवण कक्ष, राहण्याची खोली आणि एक चॅपल देखील आहे.</s><pad><pad>']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the MT\n",
    "hf_tokenizer_mt.batch_decode(batch['mt_input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> यानंतर त्यांना त्यांच्यासोबत लग्न करण्यात आलं.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> त्यामध्ये १.५ कोटींहून अधिक मर्यादित आहेत.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s> याप्रकरणी चौकशी करण्यात आले असून, पोलिसांकडून कारवाई सुरू आहे.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>.. हे ध्येय आहे, पण, त्या मर्यादित आहे की, जर तुम्हाला तुमच्या मते, तुमच्यावर तुमच्या डॉक्टरांशी बोला.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the PE\n",
    "hf_tokenizer_mt.batch_decode(post_edit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub-g21-mt-zcZ_0igR-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
